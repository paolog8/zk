Tags: #CurseOfDimensionality, #Overfitting, #PVSystems

Photovoltaic systems utilize numerous sensors, resulting in high-dimensional datasets with many features (Thakfan & Salamah, 2024). 
This volume of data can lead to the "curse of dimensionality," a state where the feature space becomes so vast and sparse that ML models struggle to find meaningful patterns.

This sparsity increases the likelihood of overfitting, where the model incorrectly learns from random noise instead of the underlying data structure (Quiles et al., 2025). 
Consequently, the model's ability to generalize and make accurate predictions on new, unseen data is significantly diminished.

## Sources

Thakfan, A. and Salamah, Y. (2024). Artificial-intelligence-based detection of defects and faults in photovoltaic systems: a survey. Energies, 17(19), 4807. https://doi.org/10.3390/en17194807

Quiles, E., Sánchez-Roca, P., & Agustí-Mercader, I. (2025). Performance optimization of machine-learning algorithms for fault detection and diagnosis in pv systems. Electronics, 14(9), 1709. https://doi.org/10.3390/electronics14091709

## Connections/Related Concepts

- Connects to: [[High Data Dimensionality and Complexity Challenge ML in PV Fault Detection]] (This is a specific manifestation of the broader challenge)
    
- Connects to: [[Autoencoders Can Mitigate High Dimensionality in PV Data]] (This note presents a direct solution to this problem)
    
- Potential future connections: Comparing different dimensionality reduction techniques (e.g., PCA vs. Autoencoders) for PV data.
    

---